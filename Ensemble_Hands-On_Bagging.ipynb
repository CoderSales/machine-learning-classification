{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: \n",
    "\n",
    "This notebook is an updated version of the notebook used in the **hands-on lecture**.\n",
    "\n",
    "The following changes have been made:\n",
    "\n",
    "1. solver hyperparameter set to 'liblinear'\n",
    "\n",
    "    * In the video, the professor used the default 'lbfgs' solver in Logistic Regression model but after an update in the sklearn,the default solver 'lbfgs' gives certain errors. To avoid any errors, the solver has been set to 'liblinear', this will result in small change in the values of metrics of the model as compared to the hands-on video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RB92HxSfxLPj"
   },
   "source": [
    "# Ensemble Hands On - Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fy_ZAgmzxLPk"
   },
   "source": [
    "We are going to build a model that predicts if someone who seeks a loan might be a defaulter or a non-defaulter. We have several independent variables like, checking account balance, credit history, purpose, loan amount etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nb_install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'notebook' already in sys.modules\n",
      "'matplotlib' already in sys.modules\n",
      "'pandas' already in sys.modules\n",
      "'seaborn' already in sys.modules\n",
      "'numpy' already in sys.modules\n",
      "'scipy' already in sys.modules\n",
      "'statsmodels' already in sys.modules\n",
      "can't find the 'scikit-learn' module\n",
      "'ipykernel' already in sys.modules\n",
      "can't find the 'nb-black' module\n",
      "'importlib.util' already in sys.modules\n",
      "'sys' already in sys.modules\n",
      "'os' already in sys.modules\n",
      "'importlib.util' already in sys.modules\n",
      "'subprocess' already in sys.modules\n",
      "'warnings' already in sys.modules\n",
      "'statsmodels.tools.sm_exceptions' already in sys.modules\n",
      "'matplotlib.pyplot' already in sys.modules\n",
      "can't find the 'sklearn.model_selection.train_test_split' module\n",
      "'statsmodels.stats.api' already in sys.modules\n",
      "'statsmodels.stats.outliers_influence' already in sys.modules\n",
      "'statsmodels.api' already in sys.modules\n",
      "'statsmodels.tools.tools' already in sys.modules\n",
      "can't find the 'sklearn.tree.DecisionTreeClassifier' module\n",
      "'sklearn.tree' already in sys.modules\n",
      "can't find the 'sklearn.model_selection.GridSearchCV' module\n",
      "can't find the 'sklearn.metrics.f1_score' module\n",
      "can't find the 'sklearn.metrics.accuracy_score' module\n",
      "can't find the 'sklearn.metrics.recall_score' module\n",
      "can't find the 'sklearn.metrics.precision_score' module\n",
      "can't find the 'sklearn.metrics.confusion_matrix' module\n",
      "can't find the 'sklearn.metrics.roc_auc_score' module\n",
      "can't find the 'sklearn.metrics.ConfusionMatrixDisplay' module\n",
      "can't find the 'sklearn.metrics.precision_recall_curve' module\n",
      "can't find the 'sklearn.metrics.roc_curve' module\n",
      "can't find the 'sklearn.metrics.make_scorer' module\n",
      "\n",
      "uninstalled modules are: ['scikit-learn', 'nb-black', 'sklearn.model_selection.train_test_split', 'sklearn.tree.DecisionTreeClassifier', 'sklearn.model_selection.GridSearchCV', 'sklearn.metrics.f1_score', 'sklearn.metrics.accuracy_score', 'sklearn.metrics.recall_score', 'sklearn.metrics.precision_score', 'sklearn.metrics.confusion_matrix', 'sklearn.metrics.roc_auc_score', 'sklearn.metrics.ConfusionMatrixDisplay', 'sklearn.metrics.precision_recall_curve', 'sklearn.metrics.roc_curve', 'sklearn.metrics.make_scorer'] \n",
      "\n",
      "scikit-learn module has been installed\n",
      "nb-black module has been installed\n",
      "sklearn.model_selection.train_test_split module has been installed\n",
      "sklearn.tree.DecisionTreeClassifier module has been installed\n",
      "sklearn.model_selection.GridSearchCV module has been installed\n",
      "sklearn.metrics.f1_score module has been installed\n",
      "sklearn.metrics.accuracy_score module has been installed\n",
      "sklearn.metrics.recall_score module has been installed\n",
      "sklearn.metrics.precision_score module has been installed\n",
      "sklearn.metrics.confusion_matrix module has been installed\n",
      "sklearn.metrics.roc_auc_score module has been installed\n",
      "sklearn.metrics.ConfusionMatrixDisplay module has been installed\n",
      "sklearn.metrics.precision_recall_curve module has been installed\n",
      "sklearn.metrics.roc_curve module has been installed\n",
      "sklearn.metrics.make_scorer module has been installed\n",
      "\n",
      " ['scikit-learn', 'nb-black', 'sklearn.model_selection.train_test_split', 'sklearn.tree.DecisionTreeClassifier', 'sklearn.model_selection.GridSearchCV', 'sklearn.metrics.f1_score', 'sklearn.metrics.accuracy_score', 'sklearn.metrics.recall_score', 'sklearn.metrics.precision_score', 'sklearn.metrics.confusion_matrix', 'sklearn.metrics.roc_auc_score', 'sklearn.metrics.ConfusionMatrixDisplay', 'sklearn.metrics.precision_recall_curve', 'sklearn.metrics.roc_curve', 'sklearn.metrics.make_scorer'] modules have just been installed\n"
     ]
    }
   ],
   "source": [
    "nb_install.installer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SFyI3CAtxLPk"
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8NjHSaCTxLPl"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m \u001b[39mimport\u001b[39;00m metrics\n",
      "File \u001b[1;32mc:\\Users\\steph\\OneDrive\\Documents\\38-ML-classification\\container\\machine-learning-classification\\.venv\\lib\\site-packages\\pandas\\__init__.py:11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39mfor\u001b[39;00m dependency \u001b[39min\u001b[39;00m hard_dependencies:\n\u001b[0;32m     10\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 11\u001b[0m         \u001b[39m__import__\u001b[39;49m(dependency)\n\u001b[0;32m     12\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     13\u001b[0m         missing_dependencies\u001b[39m.\u001b[39mappend(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mdependency\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\steph\\OneDrive\\Documents\\38-ML-classification\\container\\machine-learning-classification\\.venv\\lib\\site-packages\\numpy\\__init__.py:144\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m    143\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m compat\n\u001b[1;32m--> 144\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m lib\n\u001b[0;32m    145\u001b[0m \u001b[39m# NOTE: to be revisited following future namespace cleanup.\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[39m# See gh-14454 and gh-15672 for discussion.\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mlib\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\steph\\OneDrive\\Documents\\38-ML-classification\\container\\machine-learning-classification\\.venv\\lib\\site-packages\\numpy\\lib\\__init__.py:26\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39m# Private submodules\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[39m# load module names. See https://github.com/networkx/networkx/issues/5838\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m type_check\n\u001b[1;32m---> 26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m index_tricks\n\u001b[0;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m function_base\n\u001b[0;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m nanfunctions\n",
      "File \u001b[1;32mc:\\Users\\steph\\OneDrive\\Documents\\38-ML-classification\\container\\machine-learning-classification\\.venv\\lib\\site-packages\\numpy\\lib\\index_tricks.py:13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnumerictypes\u001b[39;00m \u001b[39mimport\u001b[39;00m find_common_type, issubdtype\n\u001b[0;32m     12\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmatrixlib\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmatrixlib\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mfunction_base\u001b[39;00m \u001b[39mimport\u001b[39;00m diff\n\u001b[0;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmultiarray\u001b[39;00m \u001b[39mimport\u001b[39;00m ravel_multi_index, unravel_index\n\u001b[0;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moverrides\u001b[39;00m \u001b[39mimport\u001b[39;00m set_module\n",
      "File \u001b[1;32mc:\\Users\\steph\\OneDrive\\Documents\\38-ML-classification\\container\\machine-learning-classification\\.venv\\lib\\site-packages\\numpy\\lib\\function_base.py:35\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mbuiltins\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[39m# needed in this module for compatibility\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhistograms\u001b[39;00m \u001b[39mimport\u001b[39;00m histogram, histogramdd  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[0;32m     38\u001b[0m array_function_dispatch \u001b[39m=\u001b[39m functools\u001b[39m.\u001b[39mpartial(\n\u001b[0;32m     39\u001b[0m     overrides\u001b[39m.\u001b[39marray_function_dispatch, module\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     42\u001b[0m __all__ \u001b[39m=\u001b[39m [\n\u001b[0;32m     43\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mselect\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpiecewise\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtrim_zeros\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcopy\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39miterable\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpercentile\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     44\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mdiff\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mgradient\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mangle\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39munwrap\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msort_complex\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdisp\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mflip\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mquantile\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     51\u001b[0m     ]\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1002\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:945\u001b[0m, in \u001b[0;36m_find_spec\u001b[1;34m(name, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1439\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1411\u001b[0m, in \u001b[0;36m_get_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1544\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(self, fullname, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:147\u001b[0m, in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We will use the same `credit data` used in decision tree hands-on lecture.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vgm9EEt5xLPo",
    "outputId": "3120b7c3-2035-4c20-9107-5db2ac686ca1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url = \"credit.csv\"\n",
    "creditData = pd.read_csv(url)\n",
    "\n",
    "#creditData = pd.read_csv(\"credit.csv\")\n",
    "creditData.head(10) #several missing values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4t1OBSqzxLPr",
    "outputId": "c5db5b2b-a257-4d03-b2cf-ef59e8bed4a2"
   },
   "outputs": [],
   "source": [
    "creditData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creditData['default'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "32heA0VFxLPt",
    "outputId": "f1119e0b-fa26-43ea-ba6c-f6d77ae2354c"
   },
   "outputs": [],
   "source": [
    "creditData.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uv_-CH_JxLPx",
    "outputId": "36a727e2-731c-4dd1-cb3f-53192e55bd1f"
   },
   "outputs": [],
   "source": [
    "creditData.info()  # many columns are of type object i.e. strings. These need to be converted to ordinal type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hVDy-BlVxLPz"
   },
   "source": [
    "Lets convert the columns with an 'object' datatype into categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KQVE5XZJxLPz",
    "outputId": "683bab0e-8751-42e5-85e0-b48d80399907"
   },
   "outputs": [],
   "source": [
    "for feature in creditData.columns: # Loop through all columns in the dataframe\n",
    "    if creditData[feature].dtype == 'object': # Only apply for columns with categorical strings\n",
    "        creditData[feature] = pd.Categorical(creditData[feature])# Replace strings with an integer\n",
    "creditData.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jf4JAhwJxLP2",
    "outputId": "4719ccee-2e82-4174-e740-ebd0d7166d2d"
   },
   "outputs": [],
   "source": [
    "print(creditData.checking_balance.value_counts())\n",
    "print(creditData.credit_history.value_counts())\n",
    "print(creditData.purpose.value_counts())\n",
    "print(creditData.savings_balance.value_counts())\n",
    "print(creditData.employment_duration.value_counts())\n",
    "print(creditData.other_credit.value_counts())\n",
    "print(creditData.housing.value_counts())\n",
    "print(creditData.job.value_counts())\n",
    "print(creditData.phone.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tgft_TIVxLP4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "replaceStruct = {\n",
    "                \"checking_balance\":     {\"< 0 DM\": 1, \"1 - 200 DM\": 2 ,\"> 200 DM\": 3 ,\"unknown\":-1},\n",
    "                \"credit_history\": {\"critical\": 1, \"poor\":2 , \"good\": 3, \"very good\": 4,\"perfect\": 5},\n",
    "                 \"savings_balance\": {\"< 100 DM\": 1, \"100 - 500 DM\":2 , \"500 - 1000 DM\": 3, \"> 1000 DM\": 4,\"unknown\": -1},\n",
    "                 \"employment_duration\":     {\"unemployed\": 1, \"< 1 year\": 2 ,\"1 - 4 years\": 3 ,\"4 - 7 years\": 4 ,\"> 7 years\": 5},\n",
    "                \"phone\":     {\"no\": 1, \"yes\": 2 },\n",
    "                #\"job\":     {\"unemployed\": 1, \"unskilled\": 2, \"skilled\": 3, \"management\": 4 },\n",
    "                \"default\":     {\"no\": 0, \"yes\": 1 } \n",
    "                    }\n",
    "oneHotCols=[\"purpose\",\"housing\",\"other_credit\",\"job\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jxeyJbJFxLP6",
    "outputId": "ec5bb8e3-b09d-4920-f84b-d85791f37ff4",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "creditData=creditData.replace(replaceStruct)\n",
    "creditData=pd.get_dummies(creditData, columns=oneHotCols)\n",
    "creditData.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PqTiaxCrxLP8",
    "outputId": "ffb94d79-da96-4923-937a-7171b38eec97"
   },
   "outputs": [],
   "source": [
    "creditData.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0L-oAMItxLP-"
   },
   "source": [
    "## Split the data into train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When data (classification) exhibit a significant imbalance in the distribution of the target classes, it is good to use stratified sampling to ensure that relative class frequencies are approximately preserved in train and test sets. \n",
    "- This is done by setting the `stratify` parameter to target variable in the train_test_split function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AWq265BvxLP_"
   },
   "outputs": [],
   "source": [
    "X = creditData.drop(\"default\" , axis=1)\n",
    "y = creditData.pop(\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8EIKHRCmxLQB"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.30, random_state=1,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before building the model, let's create functions to calculate different metrics- Accuracy, Recall and Precision and plot the confusion matrix.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to create confusion matrix\n",
    "def make_confusion_matrix(model,y_actual,labels=[1, 0]):\n",
    "    '''\n",
    "    model : classifier to predict values of X\n",
    "    y_actual : ground truth  \n",
    "    \n",
    "    '''\n",
    "    y_predict = model.predict(X_test)\n",
    "    cm=metrics.confusion_matrix( y_actual, y_predict, labels=[0, 1])\n",
    "    df_cm = pd.DataFrame(cm, index = [i for i in [\"Actual - No\",\"Actual - Yes\"]],\n",
    "                  columns = [i for i in ['Predicted - No','Predicted - Yes']])\n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cm.flatten()]\n",
    "    group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                         cm.flatten()/np.sum(cm)]\n",
    "    labels = [f\"{v1}\\n{v2}\" for v1, v2 in\n",
    "              zip(group_counts,group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    plt.figure(figsize = (10,7))\n",
    "    sns.heatmap(df_cm, annot=labels,fmt='')\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Function to calculate different metric scores of the model - Accuracy, Recall and Precision\n",
    "def get_metrics_score(model,flag=True):\n",
    "    '''\n",
    "    model : classifier to predict values of X\n",
    "\n",
    "    '''\n",
    "    # defining an empty list to store train and test results\n",
    "    score_list=[] \n",
    "    \n",
    "    #Predicting on train and tests\n",
    "    pred_train = model.predict(X_train)\n",
    "    pred_test = model.predict(X_test)\n",
    "    \n",
    "    #Accuracy of the model\n",
    "    train_acc = model.score(X_train,y_train)\n",
    "    test_acc = model.score(X_test,y_test)\n",
    "    \n",
    "    #Recall of the model\n",
    "    train_recall = metrics.recall_score(y_train,pred_train)\n",
    "    test_recall = metrics.recall_score(y_test,pred_test)\n",
    "    \n",
    "    #Precision of the model\n",
    "    train_precision = metrics.precision_score(y_train,pred_train)\n",
    "    test_precision = metrics.precision_score(y_test,pred_test)\n",
    "    \n",
    "    score_list.extend((train_acc,test_acc,train_recall,test_recall,train_precision,test_precision))\n",
    "        \n",
    "    # If the flag is set to True then only the following print statements will be dispayed. The default value is set to True.\n",
    "    if flag == True: \n",
    "        print(\"Accuracy on training set : \",model.score(X_train,y_train))\n",
    "        print(\"Accuracy on test set : \",model.score(X_test,y_test))\n",
    "        print(\"Recall on training set : \",metrics.recall_score(y_train,pred_train))\n",
    "        print(\"Recall on test set : \",metrics.recall_score(y_test,pred_test))\n",
    "        print(\"Precision on training set : \",metrics.precision_score(y_train,pred_train))\n",
    "        print(\"Precision on test set : \",metrics.precision_score(y_test,pred_test))\n",
    "    \n",
    "    return score_list # returning the list with train and test scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model\n",
    "- We are going to build 2 ensemble models here - Bagging Classifier and Random Forest Classifier.\n",
    "- First, let's build these models with default parameters and then use hyperparameter tuning to optimize the model performance.\n",
    "- We will calculate all three metrics - Accuracy, Precision and Recall but the metric of interest here is recall.\n",
    "- `Recall` - It gives the ratio of True positives to Actual positives, so high Recall implies low false negatives, i.e. low chances of predicting a defaulter as non defaulter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_estimator for bagging classifier is a decision tree by default\n",
    "bagging_estimator=BaggingClassifier(random_state=1)\n",
    "bagging_estimator.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using above defined function to get accuracy, recall and precision on train and test set\n",
    "bagging_estimator_score=get_metrics_score(bagging_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_confusion_matrix(bagging_estimator,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the random forest classifier\n",
    "rf_estimator=RandomForestClassifier(random_state=1)\n",
    "rf_estimator.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using above defined function to get accuracy, recall and precision on train and test set\n",
    "rf_estimator_score=get_metrics_score(rf_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_confusion_matrix(rf_estimator,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With default parameters:**\n",
    "\n",
    "- Both models - Bagging classifiers as well as random forest classifier are overfitting the train data.\n",
    "- Both models are giving similar performance in terms of accuracy but bagging classifier is giving better recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "### Bagging Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some of the important hyperparameters available for bagging classifier are:**\n",
    "\n",
    "- base_estimator: The base estimator to fit on random subsets of the dataset. If None(default), then the base estimator is a decision tree.\n",
    "- n_estimators: The number of trees in the forest, default = 100.\n",
    "- max_features: The number of features to consider when looking for the best split. \n",
    "- bootstrap: Whether bootstrap samples are used when building trees. If False, the entire dataset is used to build each tree, default=True.\n",
    "- bootstrap_features: If it is true, then features are drawn with replacement. Default value is False.\n",
    "- max_samples: If bootstrap is True, then the number of samples to draw from X to train each base estimator. If None (default), then draw N samples, where N is the number of observations in the train data.\n",
    "- oob_score: Whether to use out-of-bag samples to estimate the generalization accuracy, default=False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Choose the type of classifier. \n",
    "bagging_estimator_tuned = BaggingClassifier(random_state=1)\n",
    "\n",
    "# Grid of parameters to choose from\n",
    "## add from article\n",
    "parameters = {'max_samples': [0.7,0.8,0.9,1], \n",
    "              'max_features': [0.7,0.8,0.9,1],\n",
    "              'n_estimators' : [10,20,30,40,50],\n",
    "             }\n",
    "\n",
    "# Type of scoring used to compare parameter combinations\n",
    "acc_scorer = metrics.make_scorer(metrics.recall_score)\n",
    "\n",
    "# Run the grid search\n",
    "grid_obj = GridSearchCV(bagging_estimator_tuned, parameters, scoring=acc_scorer,cv=5)\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Set the clf to the best combination of parameters\n",
    "bagging_estimator_tuned = grid_obj.best_estimator_\n",
    "\n",
    "# Fit the best algorithm to the data.\n",
    "bagging_estimator_tuned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's check different metrics for bagging classifier with best hyperparameters and build a confusion matrix.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using above defined function to get accuracy, recall and precision on train and test set\n",
    "bagging_estimator_tuned_score=get_metrics_score(bagging_estimator_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_confusion_matrix(bagging_estimator_tuned,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights\n",
    "- We can see that train accuracy and recall for the bagging classifier have increased slightly after hyperparameter tuning but the test recall has decreased.\n",
    "- The model is overfitting the data, as train accuracy and recall are much higher than the test accuracy and test recall.\n",
    "- The confusion matrix shows that the model is better at identifying non-defaulters as compared to defaulters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try using logistic regression as the base estimator for bagging classifier:\n",
    "- Now, let's try and change the `base_estimator` of the bagging classifier, which is a decision tree by default.\n",
    "- We will pass the logistic regression as the base estimator for bagging classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_lr=BaggingClassifier(base_estimator=LogisticRegression(solver='liblinear',random_state=1,max_iter=1000),random_state=1)\n",
    "bagging_lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using above defined function to get accuracy, recall and precision on train and test set\n",
    "bagging_lr_score=get_metrics_score(bagging_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_confusion_matrix(bagging_lr,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights\n",
    "- Bagging classifier with logistic regression as base_estimator is not overfitting the data but the test recall is very low.\n",
    "- Ensemble models are less interpretable than decision tree but bagging classifier is even less interpretable than random forest. It does not even have a feature importance attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier\n",
    "**Now, let's see if we can get a better model by tuning the random forest classifier. Some of the important hyperparameters available for random forest classifier are:**\n",
    "\n",
    "- n_estimators: The number of trees in the forest, default = 100.\n",
    "- max_features: The number of features to consider when looking for the best split. \n",
    "- class_weight: Weights associated with classes in the form {class_label: weight}.If not given, all classes are supposed to have weight one.  \n",
    "- For example: If the frequency of class 0 is 80% and the frequency of class 1 is 20% in the data, then class 0 will become the dominant class and the model will become biased toward the dominant classes. In this case, we can pass a dictionary {0:0.2,1:0.8} to the model to specify the weight of each class and the random forest will give more weightage to class 1. \n",
    "- bootstrap: Whether bootstrap samples are used when building trees. If False, the entire dataset is used to build each tree, default=True.\n",
    "- max_samples: If bootstrap is True, then the number of samples to draw from X to train each base estimator. If None (default), then draw N samples, where N is the number of observations in the train data.\n",
    "- oob_score: Whether to use out-of-bag samples to estimate the generalization accuracy, default=False.\n",
    "\n",
    "- Note: A lot of hyperparameters of Decision Trees are also available to tune  Random Forest like max_depth, min_sample_split etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Choose the type of classifier. \n",
    "rf_estimator_tuned = RandomForestClassifier(random_state=1)\n",
    "\n",
    "# Grid of parameters to choose from\n",
    "## add from article\n",
    "parameters = {\"n_estimators\": [150,200,250],\n",
    "    \"min_samples_leaf\": np.arange(5, 10),\n",
    "    \"max_features\": np.arange(0.2, 0.7, 0.1),\n",
    "    \"max_samples\": np.arange(0.3, 0.7, 0.1),\n",
    "             }\n",
    "\n",
    "# Type of scoring used to compare parameter combinations\n",
    "acc_scorer = metrics.make_scorer(metrics.recall_score)\n",
    "\n",
    "# Run the grid search\n",
    "grid_obj = GridSearchCV(rf_estimator_tuned, parameters, scoring=acc_scorer,cv=5)\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Set the clf to the best combination of parameters\n",
    "rf_estimator_tuned = grid_obj.best_estimator_\n",
    "\n",
    "# Fit the best algorithm to the data.\n",
    "rf_estimator_tuned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using above defined function to get accuracy, recall and precision on train and test set\n",
    "rf_estimator_tuned_score=get_metrics_score(rf_estimator_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_confusion_matrix(rf_estimator_tuned,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights\n",
    "- We can see that random forest's performance has increased as compared to the random forest model with default parameters.\n",
    "- Model is slightly overfitting the data but not as much as the tuned bagging classifier.\n",
    "- The test recall is still very low. This means that the model is not good at identifying defaulters which is our primary aim here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try using class_weights for random forest:\n",
    "- The model performance is not very good. This may be due to the fact that the classes are imbalanced with 70% non-defaulters and 30% defaulters. \n",
    "\n",
    "- We should make the model aware that the class of interest here is 'defaulters'.\n",
    "\n",
    "- We can do so by passing the parameter `class_weights` available for random forest. This parameter is not available for the bagging classifier.\n",
    "\n",
    "- class_weight specifies the weights associated with classes in the form {class_label: weight}. If not given, all classes are supposed to have weight one.\n",
    "\n",
    "- We can choose class_weights={0:0.3,1:0.7} because that is the original imbalance in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the type of classifier. \n",
    "rf_estimator_weighted = RandomForestClassifier(random_state=1)\n",
    "\n",
    "# Grid of parameters to choose from\n",
    "## add from article\n",
    "parameters = {\n",
    "    \"class_weight\": [{0: 0.3, 1: 0.7}],\n",
    "    \"n_estimators\": [100,150,200,250],\n",
    "    \"min_samples_leaf\": np.arange(5, 10),\n",
    "    \"max_features\": np.arange(0.2, 0.7, 0.1),\n",
    "    \"max_samples\": np.arange(0.3, 0.7, 0.1),\n",
    "}\n",
    "\n",
    "# Type of scoring used to compare parameter combinations\n",
    "acc_scorer = metrics.make_scorer(metrics.recall_score)\n",
    "\n",
    "# Run the grid search\n",
    "grid_obj = GridSearchCV(rf_estimator_weighted, parameters, scoring=acc_scorer,cv=5)\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Set the clf to the best combination of parameters\n",
    "rf_estimator_weighted = grid_obj.best_estimator_\n",
    "\n",
    "# Fit the best algorithm to the data.\n",
    "rf_estimator_weighted.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using above defined function to get accuracy, recall and precision on train and test set\n",
    "rf_estimator_weighted_score=get_metrics_score(rf_estimator_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_confusion_matrix(rf_estimator_weighted,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights\n",
    "- The model accuracy has decreased a bit but the overfitting has also been reduced and the model is generalizing well.\n",
    "- The train and test recall both have increased significantly.\n",
    "- We can see from the confusion matrix that the random forest model with class weights is now better at identifying the defaulters as compared to other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf_estimator_weighted.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "feature_names = list(X.columns)\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='violet', align='center')\n",
    "plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Checking balance, amount and months loan duration are the top 3 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing all models till now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining list of models\n",
    "models = [bagging_estimator,bagging_estimator_tuned,bagging_lr,rf_estimator,rf_estimator_tuned,\n",
    "          rf_estimator_weighted]\n",
    "\n",
    "# defining empty lists to add train and test results\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "recall_train = []\n",
    "recall_test = []\n",
    "precision_train = []\n",
    "precision_test = []\n",
    "\n",
    "# looping through all the models to get the accuracy, precall and precision scores\n",
    "for model in models:\n",
    "    j = get_metrics_score(model,False)\n",
    "    acc_train.append(np.round(j[0],2))\n",
    "    acc_test.append(np.round(j[1],2))\n",
    "    recall_train.append(np.round(j[2],2))\n",
    "    recall_test.append(np.round(j[3],2))\n",
    "    precision_train.append(np.round(j[4],2))\n",
    "    precision_test.append(np.round(j[5],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_frame = pd.DataFrame({'Model':['Bagging classifier with default parameters','Tuned Bagging Classifier',\n",
    "                                        'Bagging classifier with base_estimator=LR', 'Random Forest with deafult parameters',\n",
    "                                         'Tuned Random Forest Classifier','Random Forest with class_weights'], \n",
    "                                          'Train_Accuracy': acc_train,'Test_Accuracy': acc_test,\n",
    "                                          'Train_Recall':recall_train,'Test_Recall':recall_test,\n",
    "                                          'Train_Precision':precision_train,'Test_Precision':precision_test}) \n",
    "comparison_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:\n",
    "- Hyperparameter tuning is tricky and exhaustive in the sense that there is no direct way to calculate how a change in the\n",
    "  hyperparameter value will reduce the loss of your model until you try those hyperparameters.\n",
    "- The final results depend on the parameters used/checked using GridSearchCV.\n",
    "- There may be yet better parameters which may result in a better accuracy and recall. Students can explore this further."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Decision_Tree_Notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "9d3efd2f2773b376bcbfafd2cf5748c36ebd086818d5a09f3b333a5e4a10f0ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
